{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Twitter_Sarcasm_Detection_Source_Code.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "ee1edf33447d4a84b4ca26f2f49a7bf9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d31ec5feadf341ed8b341dae12e948c2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_33399a44169543e6ab20b538d56921d0",
              "IPY_MODEL_037e379c01974084821fe213ebfb7b98"
            ]
          }
        },
        "d31ec5feadf341ed8b341dae12e948c2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "33399a44169543e6ab20b538d56921d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_16e55e320bc942e787cc55ac4c513b14",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1d9a85cf4ffb470e9ce87d39c0b77509"
          }
        },
        "037e379c01974084821fe213ebfb7b98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6c2001bfde8948f6b4dab123778021a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 433/433 [00:00&lt;00:00, 750B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c10da519850411ab9884943d38710b8"
          }
        },
        "16e55e320bc942e787cc55ac4c513b14": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1d9a85cf4ffb470e9ce87d39c0b77509": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6c2001bfde8948f6b4dab123778021a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c10da519850411ab9884943d38710b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "36ef1e42eea2496eb9b4dfa38029e7b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_33a1f2409f6e48b0ae4d559471fd7486",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f76f5c83d82f48138d6c6493752cb7da",
              "IPY_MODEL_ed337c85c7c1443e86c186d974b3b1f0"
            ]
          }
        },
        "33a1f2409f6e48b0ae4d559471fd7486": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f76f5c83d82f48138d6c6493752cb7da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f55ced2907914d16bb4df3d90b7d40de",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 231508,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 231508,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e69353b54ebb43238e07dcc7f6dfcd1e"
          }
        },
        "ed337c85c7c1443e86c186d974b3b1f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4145ba1c9c16484f8b9b2d0b70520d15",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 232k/232k [00:00&lt;00:00, 667kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fd52992ad604e7981a9ac8c97095af7"
          }
        },
        "f55ced2907914d16bb4df3d90b7d40de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e69353b54ebb43238e07dcc7f6dfcd1e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4145ba1c9c16484f8b9b2d0b70520d15": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fd52992ad604e7981a9ac8c97095af7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ae41c46748454066a5a026cbf1b1caed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_fdad0b036c4e4c1f9a52c78307c42dae",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5c0e11d4ed104fe98ea81ca115ce8523",
              "IPY_MODEL_45d134c2a2d3421eb8e941d7995e3ad2"
            ]
          }
        },
        "fdad0b036c4e4c1f9a52c78307c42dae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5c0e11d4ed104fe98ea81ca115ce8523": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_7381c912844047e69c63291f029bc76c",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 466062,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 466062,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7668dab104eb4494beba60795f368967"
          }
        },
        "45d134c2a2d3421eb8e941d7995e3ad2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9c5c7d0a6c05455b9eed5a10b362e0ac",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 466k/466k [02:48&lt;00:00, 2.76kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3b84520e014e46678b8e93a0e3582278"
          }
        },
        "7381c912844047e69c63291f029bc76c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7668dab104eb4494beba60795f368967": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c5c7d0a6c05455b9eed5a10b362e0ac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3b84520e014e46678b8e93a0e3582278": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bd912553603b4c828fc9ce575bda9b55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_6dde1339468b464f8cab36616448123a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2a620951a9234798b63b13bbcaa7bc90",
              "IPY_MODEL_ae0f35d77d5f4edd9f57c38ecf1b96f1"
            ]
          }
        },
        "6dde1339468b464f8cab36616448123a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2a620951a9234798b63b13bbcaa7bc90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_e45f5219346b47e5863915d0934429a6",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 440473133,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 440473133,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5fe627ab1a85444581b8f08976438c02"
          }
        },
        "ae0f35d77d5f4edd9f57c38ecf1b96f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9e96a9d98d90441598e15330b8fec2b8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:27&lt;00:00, 16.2MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9bbe7d4b7f044e9989ec4112614e7b4e"
          }
        },
        "e45f5219346b47e5863915d0934429a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5fe627ab1a85444581b8f08976438c02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9e96a9d98d90441598e15330b8fec2b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9bbe7d4b7f044e9989ec4112614e7b4e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2ccfe32c95d7440bbd50fec2b4dca588": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_97e7185f965940e996dfdb82d0752521",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dffd422375ab4fa686ad70b566ed032c",
              "IPY_MODEL_e850357a165d4c44b0d2f3e3e30fe9ce"
            ]
          }
        },
        "97e7185f965940e996dfdb82d0752521": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dffd422375ab4fa686ad70b566ed032c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_caa14ac8b8304cde97fef6dcfee80206",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 250,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1bd4fc24e10b43a382b78ba0279726e9"
          }
        },
        "e850357a165d4c44b0d2f3e3e30fe9ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_aa817ea89f7a441ebd8ef58dcab46b86",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/250 [01:06&lt;00:00,  3.75it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1fd788c4846a402099b959cabf40a32d"
          }
        },
        "caa14ac8b8304cde97fef6dcfee80206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1bd4fc24e10b43a382b78ba0279726e9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "aa817ea89f7a441ebd8ef58dcab46b86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1fd788c4846a402099b959cabf40a32d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "acbf7d96ed3741eab201cdc195fa85ea": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7efd4079be594f62a5290f634e877980",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d4fc276eeb97438b994770e5efa7441f",
              "IPY_MODEL_16b768cbbe374823a63d0c4f01837a78"
            ]
          }
        },
        "7efd4079be594f62a5290f634e877980": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d4fc276eeb97438b994770e5efa7441f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_bf7f227c47f243968f8cf1d21a1adf54",
            "_dom_classes": [],
            "description": "Iteration: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 250,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 250,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8e957e6b35cf49e596739d7c87dde6d6"
          }
        },
        "16b768cbbe374823a63d0c4f01837a78": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_71eeeaef1248498aa97b46e7e185822f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 250/250 [00:59&lt;00:00,  4.18it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_591313650d3d4667ab817a8b2c9b6571"
          }
        },
        "bf7f227c47f243968f8cf1d21a1adf54": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8e957e6b35cf49e596739d7c87dde6d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "71eeeaef1248498aa97b46e7e185822f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "591313650d3d4667ab817a8b2c9b6571": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f1b71b78fb3844b2ab946d4d16cdd889": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0991c21e3d2548b4ab357e435c4d0a0b",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_27f618ec3a3141818fa3a417b448c0a0",
              "IPY_MODEL_289fe412567849fbaaeffb256357b2bc"
            ]
          }
        },
        "0991c21e3d2548b4ab357e435c4d0a0b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "27f618ec3a3141818fa3a417b448c0a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2dc70257a14f4ca19e31d7aec6e000bc",
            "_dom_classes": [],
            "description": "Evaluating: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 32,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 32,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11ec9a1355194e72a711c62f84f51888"
          }
        },
        "289fe412567849fbaaeffb256357b2bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d137866aaf0840538f6dbf7d9133bb96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 32/32 [00:04&lt;00:00,  7.67it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_611cb406d3f84b5881ea22356735c7ae"
          }
        },
        "2dc70257a14f4ca19e31d7aec6e000bc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11ec9a1355194e72a711c62f84f51888": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d137866aaf0840538f6dbf7d9133bb96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "611cb406d3f84b5881ea22356735c7ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c9a585c8757a492b9aa726a86f36b8cd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e77cc1494f63403aac29b65f858752f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_23581ddccd4f461eb0009953dc2b8294",
              "IPY_MODEL_bd6fa9f673ba490899a1e32120cc01bd"
            ]
          }
        },
        "e77cc1494f63403aac29b65f858752f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "23581ddccd4f461eb0009953dc2b8294": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_8520358d899b4a4c8adfdeeabe8d64ec",
            "_dom_classes": [],
            "description": "Predicting: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 57,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 57,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a0e51fb74c1e4cabb368a32ffb2764cf"
          }
        },
        "bd6fa9f673ba490899a1e32120cc01bd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_b0317ff832594f3e8d6980dfefdce5a3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 57/57 [00:07&lt;00:00,  8.13it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1eb912d4d44148ca91103eeaf6b4cfaf"
          }
        },
        "8520358d899b4a4c8adfdeeabe8d64ec": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a0e51fb74c1e4cabb368a32ffb2764cf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b0317ff832594f3e8d6980dfefdce5a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1eb912d4d44148ca91103eeaf6b4cfaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuLR0BMJhIub"
      },
      "source": [
        "# Classification Competition: Twitter Sarcasm Detection\r\n",
        "### CS 410 Final Project Source Code by Yang Yang (yangy19@illinois.edu)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zgVv1JMy38Z0"
      },
      "source": [
        "## Note for Reviews\r\n",
        "\r\n",
        "- Please open this Notebook from Google Colab.\r\n",
        "\r\n",
        "- Go to **Runtime** -> **Change runtime type**, and make sure it has **GPU** selected as Hardware accelerator and **High-RAM** as Runtime shape.\r\n",
        "\r\n",
        "- Go to **Runtime** -> **Run all**. It takes approximately 5 minutes to complete. \r\n",
        "\r\n",
        "- Before you download the `answer.txt`, you can also look at the validation F1 score, which is usually ~0.83. You can use the **Table of contents** toolbar on the left to navigate to section **7. Evaluation**.\r\n",
        "\r\n",
        "- Use the **Files** toolbar on the left, go to **outputs** -> **Twitter_Sarcasm_Detection**, and you should be able to see `answer.txt`.\r\n",
        "\r\n",
        "- Thank you for reviewing my project. Please feel free to contact me if you have any questions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZIHhCYNhN-H"
      },
      "source": [
        "## Introduction \n",
        "\n",
        "In this Classification Competition, the task is to detect sarcasm in contextual Twitter text. In order to beat the baseline F1 score and improve the performance, the main model used in this project is one of the State-of-the-Art NLP models, BERT. \n",
        "\n",
        "I follow the procedures below to fine-tune and improve the model performance: \n",
        "\n",
        "(1) Adapt the BERT classifier code by Huggingface transformers and BERT example from Google Research, and modify the BERT model code to make it applicable for other BERT-based models;\n",
        "\n",
        "(2) Compare model performances of BERT, ALBERT, DistilBERT, SqueezeBERT and XLNet with same hyperparameters;\n",
        "\n",
        "(3) Optimize BERT hyperparameters;\n",
        "\n",
        "(4) Compare BERT model performances when:\n",
        "\n",
        "- Response and Context are used separately as sequence pair tasks.\n",
        "- Response and Context are concatenated and used as normal text classification tasks.\n",
        "- Only Response information is used.\n",
        "\n",
        "Finally, my best model is able to reach on the test dataset **0.763** as F1 score and beat the baseline performance (F1=**0.723**).\n",
        "\n",
        "The whole project is developed with PyTorch framework in Google Colab environment. The project documentation, voiced presentation and this source code are all available in [CourseProject GitHub Repo](https://github.com/yangyangsquare/CourseProject).\n",
        "\n",
        "### Sections\n",
        "\n",
        "1. [Library Setup](#1.-Library-Setup)\n",
        "\n",
        "2. [Dataset Loading](#2.-Dataset-Loading)\n",
        "\n",
        "3. [Parameter Setting](#3.-Parameter-Setting)\n",
        "\n",
        "4. [Classes and Functions](#4.-Classes-and-Functions)\n",
        "\n",
        "5. [Data Preparation](#5.-Data-Preparation)\n",
        "\n",
        "6. [Model Training](#6.-Model-Training)\n",
        "\n",
        "7. [Evaluation](#7.-Evaluation)\n",
        "\n",
        "8. [Prediction](#8.-Prediction)\n",
        "\n",
        "9. [Hyperparameter Tuning](#9.-Hyperparameter-Tuning)\n",
        "\n",
        "10. [References](#10.-References)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YIv7rF4V6lyE"
      },
      "source": [
        "## 1. Library Setup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42-lJ1u9IHT6",
        "outputId": "3fb780f4-769f-4c95-da8b-a6e552337aa4"
      },
      "source": [
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install jsonlines\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datasets\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/38/0c24dce24767386123d528d27109024220db0e7a04467b658d587695241a/datasets-1.1.3-py3-none-any.whl (153kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 163kB 6.2MB/s \n",
            "\u001b[?25hCollecting pyarrow>=0.17.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e1/27958a70848f8f7089bff8d6ebe42519daf01f976d28b481e1bfd52c8097/pyarrow-2.0.0-cp36-cp36m-manylinux2014_x86_64.whl (17.7MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 17.7MB 331kB/s \n",
            "\u001b[?25hRequirement already satisfied: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.11.1)\n",
            "Collecting xxhash\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f7/73/826b19f3594756cb1c6c23d2fbd8ca6a77a9cd3b650c9dec5acc85004c38/xxhash-2.0.0-cp36-cp36m-manylinux2010_x86_64.whl (242kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 245kB 56.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.5)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.8)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Installing collected packages: pyarrow, xxhash, datasets\n",
            "  Found existing installation: pyarrow 0.14.1\n",
            "    Uninstalling pyarrow-0.14.1:\n",
            "      Successfully uninstalled pyarrow-0.14.1\n",
            "Successfully installed datasets-1.1.3 pyarrow-2.0.0 xxhash-2.0.0\n",
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/db/98c3ea1a78190dac41c0127a063abf92bd01b4b0b6970a6db1c2f5b66fa0/transformers-4.0.1-py3-none-any.whl (1.4MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.4MB 6.7MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 890kB 15.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting tokenizers==0.9.4\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0f/1c/e789a8b12e28be5bc1ce2156cf87cb522b379be9cadc7ad8091a4cc107c4/tokenizers-0.9.4-cp36-cp36m-manylinux2010_x86_64.whl (2.9MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.9MB 16.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=b8dea2cdc83301171e491486659cc9a31350a9589617bdcf4fbe24052aa12b4c\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 tokenizers-0.9.4 transformers-4.0.1\n",
            "Collecting jsonlines\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/9a/ab96291470e305504aa4b7a2e0ec132e930da89eb3ca7a82fbe03167c131/jsonlines-1.2.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from jsonlines) (1.15.0)\n",
            "Installing collected packages: jsonlines\n",
            "Successfully installed jsonlines-1.2.0\n",
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 4.9MB/s \n",
            "\u001b[?25hCollecting boto3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/3e/3a4546165383a5fc9f6f7ba15a261c768aee10662bb06105100d859e8940/boto3-1.16.35-py2.py3-none-any.whl (129kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 133kB 28.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.41.1)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.7.0+cu101)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.18.5)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2019.12.20)\n",
            "Collecting s3transfer<0.4.0,>=0.3.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 71kB 10.2MB/s \n",
            "\u001b[?25hCollecting botocore<1.20.0,>=1.19.35\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/cd/f8/d355891fc244cb31ad8a30ce452efbf2b31a48da0239f220a871c54fe829/botocore-1.19.35-py2.py3-none-any.whl (7.1MB)\n",
            "\u001b[K     |â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 7.1MB 54.2MB/s \n",
            "\u001b[?25hCollecting jmespath<1.0.0,>=0.7.1\n",
            "  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (3.7.4.3)\n",
            "Requirement already satisfied: dataclasses in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from torch>=0.4.1->pytorch_pretrained_bert) (0.16.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2020.12.5)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.20.0,>=1.19.35->boto3->pytorch_pretrained_bert) (2.8.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.20.0,>=1.19.35->boto3->pytorch_pretrained_bert) (1.15.0)\n",
            "\u001b[31mERROR: botocore 1.19.35 has requirement urllib3<1.27,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n",
            "Installing collected packages: jmespath, botocore, s3transfer, boto3, pytorch-pretrained-bert\n",
            "Successfully installed boto3-1.16.35 botocore-1.19.35 jmespath-0.10.0 pytorch-pretrained-bert-0.6.2 s3transfer-0.3.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KE_TpNaSZQ5n"
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import csv\n",
        "import sys\n",
        "import logging\n",
        "import random\n",
        "import jsonlines\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import matthews_corrcoef, confusion_matrix\n",
        "from tqdm import tqdm_notebook, tqdm, trange\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler, TensorDataset\n",
        "from transformers import AutoConfig, AutoModel, AutoTokenizer, AutoModelForSequenceClassification\n",
        "from pytorch_pretrained_bert.optimization import BertAdam, WarmupLinearSchedule\n",
        "from multiprocessing import Pool, cpu_count"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aF8IWdEowPP-",
        "outputId": "83e2062b-e048-400f-c29c-8c50377049c9"
      },
      "source": [
        "# Check if using 100% of GPU memory for running the code\n",
        "# from https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb\n",
        "!ln -sf /opt/bin/nvidia-smi /usr/bin/nvidia-smi\n",
        "!pip -q install gputil\n",
        "!pip -q install psutil\n",
        "!pip -q install humanize\n",
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "\n",
        "gpu = GPUs[0]\n",
        "def printm():\n",
        " process = psutil.Process(os.getpid())\n",
        " print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" | Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        " print(\"GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB\".format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "printm()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for gputil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Gen RAM Free: 26.2 GB  | Proc size: 543.5 MB\n",
            "GPU RAM Free: 16270MB | Used: 10MB | Util   0% | Total 16280MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yoGB7Arrwb4A"
      },
      "source": [
        "In case GPU utilisation (Util) is not at 0%, uncomment and run the following line to kill all processes to get the full GPU afterwards. Make sure to comment out the line again to not constantly crash the notebook on purpose."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CNdVkubWwdiD"
      },
      "source": [
        "# !kill -9 -1"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lpKx43Iq6znw"
      },
      "source": [
        "## 2. Dataset Loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YyWO128Mh_D7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6e2180b-5869-4f24-c763-c217fa345e0e"
      },
      "source": [
        "# Copy data files from github to Google Colab\n",
        "!git clone https://github.com/yangyangsquare/CourseProject.git"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'CourseProject'...\n",
            "remote: Enumerating objects: 53, done.\u001b[K\n",
            "remote: Total 53 (delta 0), reused 0 (delta 0), pack-reused 53\u001b[K\n",
            "Unpacking objects: 100% (53/53), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OCA-bKfuEbjH"
      },
      "source": [
        "# Convert and split dataset from .jsonl files to dataframes\n",
        "df_train = pd.DataFrame()\n",
        "df_test = pd.DataFrame()\n",
        "\n",
        "with jsonlines.open('CourseProject/data/train.jsonl') as f:\n",
        "    for obj in f:\n",
        "        df_train = df_train.append(obj, ignore_index=True)\n",
        "\n",
        "with jsonlines.open('CourseProject/data/test.jsonl') as f:\n",
        "    for obj in f:\n",
        "        df_test = df_test.append(obj, ignore_index=True)\n",
        "\n",
        "df_train, df_val = train_test_split(df_train, test_size = 0.2, random_state=2020)\n",
        "\n",
        "df_train['idx'] = df_train.index\n",
        "df_val['idx'] = df_val.index\n",
        "df_test['idx'] = df_test.index\n",
        "\n",
        "df_train = df_train.reset_index(drop=True)\n",
        "df_val = df_val.reset_index(drop=True)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "virJHDmXduVS",
        "outputId": "139970ad-487e-4695-c54a-48b9da8e16d5"
      },
      "source": [
        "print(df_train.shape)\r\n",
        "print(df_val.shape)\r\n",
        "print(df_test.shape)\r\n",
        "\r\n",
        "print(len(df_train[df_train['label'] == 'NOT_SARCASM']))\r\n",
        "print(len(df_train[df_train['label'] == 'SARCASM']))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(4000, 4)\n",
            "(1000, 4)\n",
            "(1800, 4)\n",
            "2010\n",
            "1990\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "irj7itV0UCF_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "ca895472-50bc-45a9-e57b-c31b900c06be"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>label</th>\n",
              "      <th>response</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Continuing to map out the general whereabouts...</td>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER @USER @USER I like it as well ! We did s...</td>\n",
              "      <td>3966</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[I â€™ m confused as to how you can be in this i...</td>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER @USER Also , the type of guy who wants h...</td>\n",
              "      <td>4268</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@USER stated \" The Majority of Americans love...</td>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER @USER I can only imagine the fun KingGeo...</td>\n",
              "      <td>2048</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Progressives Admit They're Just Not Used To K...</td>\n",
              "      <td>NOT_SARCASM</td>\n",
              "      <td>@USER @USER @USER I don't agree with killing t...</td>\n",
              "      <td>4935</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[And you better believe I ain't going to follo...</td>\n",
              "      <td>SARCASM</td>\n",
              "      <td>@USER please don't call your chihuahua \" bear ...</td>\n",
              "      <td>1005</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ...   idx\n",
              "0  [Continuing to map out the general whereabouts...  ...  3966\n",
              "1  [I â€™ m confused as to how you can be in this i...  ...  4268\n",
              "2  [@USER stated \" The Majority of Americans love...  ...  2048\n",
              "3  [Progressives Admit They're Just Not Used To K...  ...  4935\n",
              "4  [And you better believe I ain't going to follo...  ...  1005\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zBS-D4HkHj8z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "553e7fa5-26bf-4ff9-872a-7b15478f492f"
      },
      "source": [
        "df_test.head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>context</th>\n",
              "      <th>id</th>\n",
              "      <th>response</th>\n",
              "      <th>idx</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[Well now that â€™ s problematic AF &lt;URL&gt;, @USER...</td>\n",
              "      <td>twitter_1</td>\n",
              "      <td>@USER @USER @USER My 3 year old , that just fi...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[Last week the Fake News said that a section o...</td>\n",
              "      <td>twitter_2</td>\n",
              "      <td>@USER @USER How many verifiable lies has he to...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@USER Let â€™ s Aplaud Brett When he deserves i...</td>\n",
              "      <td>twitter_3</td>\n",
              "      <td>@USER @USER @USER Maybe Docs just a scrub of a...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[Women generally hate this president . What's ...</td>\n",
              "      <td>twitter_4</td>\n",
              "      <td>@USER @USER is just a cover up for the real ha...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[Dear media Remoaners , you excitedly sharing ...</td>\n",
              "      <td>twitter_5</td>\n",
              "      <td>@USER @USER @USER The irony being that he even...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                             context  ... idx\n",
              "0  [Well now that â€™ s problematic AF <URL>, @USER...  ...   0\n",
              "1  [Last week the Fake News said that a section o...  ...   1\n",
              "2  [@USER Let â€™ s Aplaud Brett When he deserves i...  ...   2\n",
              "3  [Women generally hate this president . What's ...  ...   3\n",
              "4  [Dear media Remoaners , you excitedly sharing ...  ...   4\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ajkeS4-PDZjW"
      },
      "source": [
        "df_train.to_csv('CourseProject/data/train.tsv', sep='\\t', index=False, header=False)\n",
        "df_val.to_csv('CourseProject/data/val.tsv', sep='\\t', index=False, header=False)\n",
        "df_test.to_csv('CourseProject/data/test.tsv', sep='\\t', index=False, header=False)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-hln-PjaA9QE"
      },
      "source": [
        "## 3. Parameter Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "McAlQGftLpCu"
      },
      "source": [
        "# OPTIONAL: if you want to have more information on what's happening, activate the logger as follows\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# The method of utilizing \"Response\" and \"Context\" data. Select from the list:\n",
        "# 1) \"ResponseContext_Separate\": text_a = Response, text_b = Context\n",
        "# 2) \"ResponseContext_Connect\": text_a = Response + Context, text_b = None\n",
        "# 3) \"Response_Only\": text_a = Response, text_b = None\n",
        "METHOD = \"ResponseContext_Separate\"\n",
        "\n",
        "# Pre-trained model selected in the list:\n",
        "BERT_PRETRAINED = ['bert-base-uncased', 'bert-large-uncased', 'bert-base-cased', 'bert-large-cased']\n",
        "distilBERT_PRETRAINED = ['distilbert-base-uncased', 'distilbert-base-uncased-distilled-squad', 'distilbert-base-cased', 'distilbert-base-cased-distilled-squad']\n",
        "alBERT_PRETRAINED = ['albert-base-v1', 'albert-base-v2', 'albert-large-v1', 'albert-large-v2']\n",
        "XLNet_PRETRAINED = ['xlnet-base-cased', 'xlnet-large-cased']\n",
        "SqueezeBERT_PRETRAINED = ['squeezebert/squeezebert-uncased', 'squeezebert/squeezebert-mnli', 'squeezebert/squeezebert-mnli-headless']\n",
        "\n",
        "BERT_MODEL = 'bert-base-uncased'\n",
        "\n",
        "# The name of the task to train.\n",
        "TASK_NAME = \"Twitter_Sarcasm_Detection\"\n",
        "\n",
        "# The input data dir. contains the .tsv files (or other data files) for the task.\n",
        "DATA_DIR = 'CourseProject/data/'\n",
        "\n",
        "# The output directory is where the fine-tuned model and checkpoints will be written.\n",
        "OUTPUT_DIR = f'outputs/{TASK_NAME}/'\n",
        "\n",
        "# The reports directory is where the evaluation reports will be written to.\n",
        "REPORTS_DIR = f'reports/{TASK_NAME}_evaluation_report/'\n",
        "\n",
        "# This is where BERT will look for pre-trained models to load parameters from.\n",
        "CACHE_DIR = 'cache/'\n",
        "\n",
        "# The maximum total input sequence length after WordPiece tokenization.\n",
        "# Sequences longer than this will be truncated, and sequences shorter than this will be padded.\n",
        "MAX_SEQ_LENGTH = 128\n",
        "\n",
        "TRAIN_BATCH_SIZE = 16\n",
        "VAL_BATCH_SIZE = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "NUM_TRAIN_EPOCHS = 2\n",
        "RANDOM_SEED = 2020\n",
        "GRADIENT_ACCUMULATION_STEPS = 2\n",
        "WARMUP_PROPORTION = 0.1\n",
        "\n",
        "OUTPUT_MODE = \"classification\"\n",
        "CONFIG_NAME = \"config.json\"\n",
        "WEIGHTS_NAME = \"pytorch_model.bin\"\n",
        "output_mode = OUTPUT_MODE\n",
        "cache_dir = CACHE_DIR\n",
        "\n",
        "if os.path.exists(REPORTS_DIR) and os.listdir(REPORTS_DIR):\n",
        "        REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
        "        os.makedirs(REPORTS_DIR)\n",
        "if not os.path.exists(REPORTS_DIR):\n",
        "    os.makedirs(REPORTS_DIR)\n",
        "    REPORTS_DIR += f'/report_{len(os.listdir(REPORTS_DIR))}'\n",
        "    os.makedirs(REPORTS_DIR)\n",
        "\n",
        "if os.path.exists(OUTPUT_DIR) and os.listdir(OUTPUT_DIR):\n",
        "        raise ValueError(\"Output directory ({}) already exists and is not empty.\".format(OUTPUT_DIR))\n",
        "if not os.path.exists(OUTPUT_DIR):\n",
        "    os.makedirs(OUTPUT_DIR)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TWJfh6DV7CB5"
      },
      "source": [
        "## 4. Classes and Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W39ZGYJ4BqZU"
      },
      "source": [
        "class InputExample(object):\n",
        "    \"\"\"A single training/test example for simple sequence classification.\"\"\"\n",
        "\n",
        "    def __init__(self, guid, text_a, text_b=None, label=None):\n",
        "        \"\"\"Constructs a InputExample.\n",
        "        Args:\n",
        "            guid: Unique id for the example.\n",
        "            text_a: string. The untokenized text of the first sequence. For single\n",
        "            sequence tasks, only this sequence must be specified.\n",
        "            text_b: (Optional) string. The untokenized text of the second sequence.\n",
        "            Only must be specified for sequence pair tasks.\n",
        "            label: (Optional) string. The label of the example. This should be\n",
        "            specified for train and dev examples, but not for test examples.\n",
        "        \"\"\"\n",
        "        self.guid = guid\n",
        "        self.text_a = text_a\n",
        "        self.text_b = text_b\n",
        "        self.label = label\n",
        "\n",
        "\n",
        "class DataProcessor(object):\n",
        "    \"\"\"Base class for data converters for sequence classification data sets.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the train set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_val_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the val set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "        \"\"\"Gets a collection of `InputExample`s for the dev set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    def get_labels(self):\n",
        "        \"\"\"Gets the list of labels for this data set.\"\"\"\n",
        "        raise NotImplementedError()\n",
        "\n",
        "    @classmethod\n",
        "    def _read_tsv(cls, input_file, quotechar=None):\n",
        "        \"\"\"Reads a tab separated value file.\"\"\"\n",
        "        with open(input_file, \"r\", encoding=\"utf-8\") as f:\n",
        "            reader = csv.reader(f, delimiter=\"\\t\", quotechar=quotechar)\n",
        "            lines = []\n",
        "            for line in reader:\n",
        "                if sys.version_info[0] == 2:\n",
        "                    line = list(unicode(cell, 'utf-8') for cell in line)\n",
        "                lines.append(line)\n",
        "            return lines\n",
        "\n",
        "\n",
        "class BinaryClassificationProcessor(DataProcessor):\n",
        "    \"\"\"Processor for binary classification dataset.\"\"\"\n",
        "\n",
        "    def get_train_examples(self, data_dir):\n",
        "      \"\"\"See base class.\"\"\"\n",
        "      return self._create_examples(\n",
        "          self._read_tsv(os.path.join(data_dir, \"train.tsv\")), \"train\")\n",
        "\n",
        "    def get_val_examples(self, data_dir):\n",
        "      \"\"\"See base class.\"\"\"\n",
        "      return self._create_examples(\n",
        "          self._read_tsv(os.path.join(data_dir, \"val.tsv\")), \"val\")\n",
        "\n",
        "    def get_test_examples(self, data_dir):\n",
        "      \"\"\"See base class.\"\"\"\n",
        "      return self._create_examples(\n",
        "          self._read_tsv(os.path.join(data_dir, \"test.tsv\")), \"test\")\n",
        "\n",
        "    def get_labels(self):\n",
        "      \"\"\"See base class.\"\"\"\n",
        "      return [\"NOT_SARCASM\", \"SARCASM\"]\n",
        "\n",
        "    def _create_examples(self, lines, set_type):\n",
        "      \"\"\"Creates examples for the training and dev sets.\"\"\"\n",
        "      examples = []\n",
        "      for (i, line) in enumerate(lines):\n",
        "        guid = \"%s-%s\" % (set_type, i)\n",
        "\n",
        "        if METHOD == \"ResponseContext_Separate\":\n",
        "          text_a = line[2]\n",
        "          text_b = line[0]\n",
        "        elif METHOD == \"ResponseContext_Connect\":\n",
        "          text_a = line[2] + line[0]\n",
        "          text_b = None\n",
        "        elif METHOD == \"Response_Only\":\n",
        "          text_a = line[2]\n",
        "          text_b = None\n",
        "\n",
        "        if set_type == \"test\":\n",
        "          label = \"SARCASM\"\n",
        "        else:\n",
        "          label = lines[i][1]\n",
        "        examples.append(\n",
        "            InputExample(guid=guid, text_a=text_a, text_b=text_b, label=label))\n",
        "      return examples"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UL4hhyO_IznV"
      },
      "source": [
        "class InputFeatures(object):\n",
        "    \"\"\"A single set of features of data.\"\"\"\n",
        "\n",
        "    def __init__(self, input_ids, input_mask, segment_ids, label_id):\n",
        "        self.input_ids = input_ids\n",
        "        self.input_mask = input_mask\n",
        "        self.segment_ids = segment_ids\n",
        "        self.label_id = label_id\n",
        "\n",
        "def _truncate_seq_pair(tokens_a, tokens_b, max_length):\n",
        "    \"\"\"Truncates a sequence pair in place to the maximum length.\"\"\"\n",
        "\n",
        "    # This is a simple heuristic which will always truncate the longer sequence\n",
        "    # one token at a time. This makes more sense than truncating an equal percent\n",
        "    # of tokens from each, since if one sequence is very short then each token\n",
        "    # that's truncated likely contains more information than a longer sequence.\n",
        "    while True:\n",
        "        total_length = len(tokens_a) + len(tokens_b)\n",
        "        if total_length <= max_length:\n",
        "            break\n",
        "        if len(tokens_a) > len(tokens_b):\n",
        "            tokens_a.pop()\n",
        "        else:\n",
        "            tokens_b.pop()\n",
        "\n",
        "def convert_example_to_feature(example_row):\n",
        "    \n",
        "    example, label_map, max_seq_length, tokenizer, output_mode = example_row\n",
        "\n",
        "    tokens_a = tokenizer.tokenize(example.text_a)\n",
        "    tokens_b = None\n",
        "    if example.text_b:\n",
        "        tokens_b = tokenizer.tokenize(example.text_b)\n",
        "        # Modifies `tokens_a` and `tokens_b` in place so that the total\n",
        "        # length is less than the specified length.\n",
        "        # Account for [CLS], [SEP], [SEP] with \"- 3\"\n",
        "        _truncate_seq_pair(tokens_a, tokens_b, max_seq_length - 3)\n",
        "    else:\n",
        "        # Account for [CLS] and [SEP] with \"- 2\"\n",
        "        if len(tokens_a) > max_seq_length - 2:\n",
        "            tokens_a = tokens_a[:(max_seq_length - 2)]\n",
        "\n",
        "    tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"]\n",
        "    segment_ids = [0] * len(tokens)\n",
        "\n",
        "    if tokens_b:\n",
        "        tokens += tokens_b + [\"[SEP]\"]\n",
        "        segment_ids += [1] * (len(tokens_b) + 1)\n",
        "\n",
        "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
        "\n",
        "    # The mask has 1 for real tokens and 0 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [1] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length.\n",
        "    padding = [0] * (max_seq_length - len(input_ids))\n",
        "    input_ids += padding\n",
        "    input_mask += padding\n",
        "    segment_ids += padding\n",
        "\n",
        "    assert len(input_ids) == max_seq_length\n",
        "    assert len(input_mask) == max_seq_length\n",
        "    assert len(segment_ids) == max_seq_length\n",
        "\n",
        "    if output_mode == \"classification\":\n",
        "        label_id = label_map[example.label]\n",
        "    elif output_mode == \"regression\":\n",
        "        label_id = float(example.label)\n",
        "    else:\n",
        "        raise KeyError(output_mode)\n",
        "\n",
        "    return InputFeatures(input_ids=input_ids,\n",
        "                         input_mask=input_mask,\n",
        "                         segment_ids=segment_ids,\n",
        "                         label_id=label_id)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZaGLU-F0uMX"
      },
      "source": [
        "def set_seed(seed):\n",
        "    \"\"\" Set all seeds to make results reproducible \"\"\"\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    np.random.seed(seed)\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CMp670ZlNs2n"
      },
      "source": [
        "def get_eval_report(task_name, labels, preds, batch_size, lr, ep, gas):\n",
        "    mcc = matthews_corrcoef(labels, preds)\n",
        "    tn, fp, fn, tp = confusion_matrix(labels, preds).ravel()\n",
        "    return {\n",
        "        \"task\": task_name,\n",
        "        \"Batch Size\": batch_size,\n",
        "        \"Learning Rate\": lr,\n",
        "        \"Epochs\": ep,\n",
        "        \"Gradient Accumulation Steps\": gas,\n",
        "        \"mcc\": mcc,\n",
        "        \"tp\": tp,\n",
        "        \"tn\": tn,\n",
        "        \"fp\": fp,\n",
        "        \"fn\": fn,\n",
        "        \"Precision\": tp / (tp+fp),\n",
        "        \"Recall\": tp / (tp+fn),\n",
        "        \"F1\": 2*tp / (2*tp + fp + fn)\n",
        "    }\n",
        "\n",
        "def compute_metrics(task_name, labels, preds, batch_size, lr, ep, gas):\n",
        "    assert len(preds) == len(labels)\n",
        "    return get_eval_report(task_name, labels, preds, batch_size, lr, ep, gas)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OWpmT7ItzABY"
      },
      "source": [
        "class CSVLogger():\n",
        "    def __init__(self, filename='log.csv', fieldnames=['epoch']):\n",
        "\n",
        "        self.filename = filename\n",
        "        self.csv_file = open(filename, 'w')\n",
        "\n",
        "        # Write model configuration at top of csv\n",
        "        writer = csv.writer(self.csv_file)\n",
        "\n",
        "        self.writer = csv.DictWriter(self.csv_file, fieldnames=fieldnames)\n",
        "        self.writer.writeheader()\n",
        "\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def writerow(self, row):\n",
        "        self.writer.writerow(row)\n",
        "        self.csv_file.flush()\n",
        "\n",
        "    def close(self):\n",
        "        self.csv_file.close()"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeTXj07xtMuI"
      },
      "source": [
        "## 5. Data Preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoJ-jHLwLJNR",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284,
          "referenced_widgets": [
            "ee1edf33447d4a84b4ca26f2f49a7bf9",
            "d31ec5feadf341ed8b341dae12e948c2",
            "33399a44169543e6ab20b538d56921d0",
            "037e379c01974084821fe213ebfb7b98",
            "16e55e320bc942e787cc55ac4c513b14",
            "1d9a85cf4ffb470e9ce87d39c0b77509",
            "6c2001bfde8948f6b4dab123778021a3",
            "8c10da519850411ab9884943d38710b8",
            "36ef1e42eea2496eb9b4dfa38029e7b1",
            "33a1f2409f6e48b0ae4d559471fd7486",
            "f76f5c83d82f48138d6c6493752cb7da",
            "ed337c85c7c1443e86c186d974b3b1f0",
            "f55ced2907914d16bb4df3d90b7d40de",
            "e69353b54ebb43238e07dcc7f6dfcd1e",
            "4145ba1c9c16484f8b9b2d0b70520d15",
            "5fd52992ad604e7981a9ac8c97095af7",
            "ae41c46748454066a5a026cbf1b1caed",
            "fdad0b036c4e4c1f9a52c78307c42dae",
            "5c0e11d4ed104fe98ea81ca115ce8523",
            "45d134c2a2d3421eb8e941d7995e3ad2",
            "7381c912844047e69c63291f029bc76c",
            "7668dab104eb4494beba60795f368967",
            "9c5c7d0a6c05455b9eed5a10b362e0ac",
            "3b84520e014e46678b8e93a0e3582278"
          ]
        },
        "outputId": "c8d8ee98-ddc2-4ea2-e9ec-94fb19586c41"
      },
      "source": [
        "set_seed(2020)\n",
        "\n",
        "processor = BinaryClassificationProcessor()\n",
        "train_examples = processor.get_train_examples(DATA_DIR)\n",
        "train_examples_len = len(train_examples)\n",
        "val_examples = processor.get_val_examples(DATA_DIR)\n",
        "val_examples_len = len(val_examples)\n",
        "test_examples = processor.get_test_examples(DATA_DIR)\n",
        "test_examples_len = len(test_examples)\n",
        "\n",
        "label_list = processor.get_labels()\n",
        "num_labels = len(label_list)\n",
        "\n",
        "num_train_optimization_steps = int(\n",
        "    train_examples_len / TRAIN_BATCH_SIZE / GRADIENT_ACCUMULATION_STEPS) * NUM_TRAIN_EPOCHS\n",
        "\n",
        "# Load pre-trained model tokenizer (vocabulary)\n",
        "tokenizer = AutoTokenizer.from_pretrained(BERT_MODEL, do_lower_case=False)\n",
        "\n",
        "label_map = {label: i for i, label in enumerate(label_list)}\n",
        "train_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in train_examples]\n",
        "val_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in val_examples]\n",
        "test_examples_for_processing = [(example, label_map, MAX_SEQ_LENGTH, tokenizer, OUTPUT_MODE) for example in test_examples]"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140470199514952 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ee1edf33447d4a84b4ca26f2f49a7bf9",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_â€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140470199514952 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.637c6035640bacb831febcc2b7f7bee0a96f9b30c2d7e9ef84082d9f252f3170.lock\n",
            "INFO:filelock:Lock 140470199514952 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "36ef1e42eea2496eb9b4dfa38029e7b1",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140470199514952 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
            "INFO:filelock:Lock 140470191105304 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ae41c46748454066a5a026cbf1b1caed",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=466062.0, style=ProgressStyle(descriptiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140470191105304 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWISHhmaMRXH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5d44874-bfe0-46a8-8cd0-68217bf94791"
      },
      "source": [
        "process_count = cpu_count() - 1\n",
        "if __name__ ==  '__main__':\n",
        "    print(f'Preparing to convert {train_examples_len} train examples..')\n",
        "    print(f'Spawning {process_count} processes..')\n",
        "    with Pool(process_count) as p:\n",
        "        train_features = list(tqdm(p.imap(convert_example_to_feature, train_examples_for_processing), total=train_examples_len))\n",
        "\n",
        "    print()\n",
        "    print(f'Preparing to convert {val_examples_len} validation examples..')\n",
        "    print(f'Spawning {process_count} processes..')\n",
        "    with Pool(process_count) as p:\n",
        "        val_features = list(tqdm(p.imap(convert_example_to_feature, val_examples_for_processing), total=val_examples_len))\n",
        "\n",
        "    print()\n",
        "    print(f'Preparing to convert {test_examples_len} test examples..')\n",
        "    print(f'Spawning {process_count} processes..')\n",
        "    with Pool(process_count) as p:\n",
        "        test_features = list(tqdm(p.imap(convert_example_to_feature, test_examples_for_processing), total=test_examples_len))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Preparing to convert 4000 train examples..\n",
            "Spawning 3 processes..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4000/4000 [00:36<00:00, 110.05it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing to convert 1000 validation examples..\n",
            "Spawning 3 processes..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1000/1000 [00:09<00:00, 108.84it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Preparing to convert 1800 test examples..\n",
            "Spawning 3 processes..\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1800/1800 [00:16<00:00, 109.48it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cCcPhd1fMZsb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "bd912553603b4c828fc9ce575bda9b55",
            "6dde1339468b464f8cab36616448123a",
            "2a620951a9234798b63b13bbcaa7bc90",
            "ae0f35d77d5f4edd9f57c38ecf1b96f1",
            "e45f5219346b47e5863915d0934429a6",
            "5fe627ab1a85444581b8f08976438c02",
            "9e96a9d98d90441598e15330b8fec2b8",
            "9bbe7d4b7f044e9989ec4112614e7b4e"
          ]
        },
        "outputId": "c07f4712-d84f-41a4-bc10-03be0229926c"
      },
      "source": [
        "# Load pre-trained model (weights)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(BERT_MODEL)\n",
        "model.to(device)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140470191105584 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bd912553603b4c828fc9ce575bda9b55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descriâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:filelock:Lock 140470191105584 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WakITJXoMkS0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42aa9229-c1b3-4b23-f03d-9d43d21c544b"
      },
      "source": [
        "logger = logging.getLogger()\n",
        "\n",
        "param_optimizer = list(model.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "    ]\n",
        "  \n",
        "optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "                     lr=LEARNING_RATE,\n",
        "                     warmup=WARMUP_PROPORTION,\n",
        "                     t_total=num_train_optimization_steps)\n",
        "\n",
        "logger.info(\"  Num examples = %d\", train_examples_len)\n",
        "logger.info(\"  Batch size = %d\", TRAIN_BATCH_SIZE)\n",
        "logger.info(\"  Num steps = %d\", num_train_optimization_steps)\n",
        "all_input_ids = torch.tensor([f.input_ids for f in train_features], dtype=torch.long)\n",
        "all_input_mask = torch.tensor([f.input_mask for f in train_features], dtype=torch.long)\n",
        "all_segment_ids = torch.tensor([f.segment_ids for f in train_features], dtype=torch.long)\n",
        "\n",
        "val_input_ids = torch.tensor([f.input_ids for f in val_features], dtype=torch.long)\n",
        "val_input_mask = torch.tensor([f.input_mask for f in val_features], dtype=torch.long)\n",
        "val_segment_ids = torch.tensor([f.segment_ids for f in val_features], dtype=torch.long)\n",
        "\n",
        "test_input_ids = torch.tensor([f.input_ids for f in test_features], dtype=torch.long)\n",
        "test_input_mask = torch.tensor([f.input_mask for f in test_features], dtype=torch.long)\n",
        "test_segment_ids = torch.tensor([f.segment_ids for f in test_features], dtype=torch.long)\n",
        "\n",
        "if OUTPUT_MODE == \"classification\":\n",
        "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.long)\n",
        "    val_label_ids = torch.tensor([f.label_id for f in val_features], dtype=torch.long)\n",
        "elif OUTPUT_MODE == \"regression\":\n",
        "    all_label_ids = torch.tensor([f.label_id for f in train_features], dtype=torch.float)\n",
        "    val_label_ids = torch.tensor([f.label_id for f in val_features], dtype=torch.float)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "INFO:root:  Num examples = 4000\n",
            "INFO:root:  Batch size = 16\n",
            "INFO:root:  Num steps = 250\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jhxIQmLIMzc9"
      },
      "source": [
        "train_data = TensorDataset(all_input_ids, all_input_mask, all_segment_ids, all_label_ids)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=TRAIN_BATCH_SIZE)\n",
        "\n",
        "val_data = TensorDataset(val_input_ids, val_input_mask, val_segment_ids, val_label_ids)\n",
        "val_sampler = SequentialSampler(val_data)\n",
        "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=VAL_BATCH_SIZE)\n",
        "\n",
        "test_data = TensorDataset(test_input_ids, test_input_mask, test_segment_ids)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=VAL_BATCH_SIZE)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkxMrm5xUDox"
      },
      "source": [
        "## 6. Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4OcYscsM43N",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "2ccfe32c95d7440bbd50fec2b4dca588",
            "97e7185f965940e996dfdb82d0752521",
            "dffd422375ab4fa686ad70b566ed032c",
            "e850357a165d4c44b0d2f3e3e30fe9ce",
            "caa14ac8b8304cde97fef6dcfee80206",
            "1bd4fc24e10b43a382b78ba0279726e9",
            "aa817ea89f7a441ebd8ef58dcab46b86",
            "1fd788c4846a402099b959cabf40a32d",
            "acbf7d96ed3741eab201cdc195fa85ea",
            "7efd4079be594f62a5290f634e877980",
            "d4fc276eeb97438b994770e5efa7441f",
            "16b768cbbe374823a63d0c4f01837a78",
            "bf7f227c47f243968f8cf1d21a1adf54",
            "8e957e6b35cf49e596739d7c87dde6d6",
            "71eeeaef1248498aa97b46e7e185822f",
            "591313650d3d4667ab817a8b2c9b6571"
          ]
        },
        "outputId": "49504715-9654-4ff0-8092-ff295b74cce3"
      },
      "source": [
        "model.train()\n",
        "global_step = 0\n",
        "\n",
        "for _ in trange(int(NUM_TRAIN_EPOCHS), desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples = 0\n",
        "    nb_tr_steps = 0\n",
        "    for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "        if BERT_MODEL in (BERT_PRETRAINED + alBERT_PRETRAINED + SqueezeBERT_PRETRAINED):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
        "        elif BERT_MODEL in (distilBERT_PRETRAINED + XLNet_PRETRAINED):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask, labels=label_ids)\n",
        "\n",
        "        logits = outputs.logits\n",
        "        loss = outputs.loss\n",
        "\n",
        "        if GRADIENT_ACCUMULATION_STEPS > 1:\n",
        "            loss = loss / GRADIENT_ACCUMULATION_STEPS\n",
        "\n",
        "        print(loss)\n",
        "        loss.backward()\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        if (step + 1) % GRADIENT_ACCUMULATION_STEPS == 0:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            global_step += 1\n",
        "\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  \n",
        "\n",
        "output_model_file = os.path.join(OUTPUT_DIR, WEIGHTS_NAME)\n",
        "output_config_file = os.path.join(OUTPUT_DIR, CONFIG_NAME)\n",
        "\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(OUTPUT_DIR)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/2 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:8: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2ccfe32c95d7440bbd50fec2b4dca588",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=250.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3206, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/pytorch_pretrained_bert/optimization.py:275: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha) (Triggered internally at  /pytorch/torch/csrc/utils/python_arg_parser.cpp:882.)\n",
            "  next_m.mul_(beta1).add_(1 - beta1, grad)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.3241, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3531, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3285, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3605, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3281, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3504, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3395, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3677, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3362, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3554, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3294, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3382, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3295, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3422, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3345, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2901, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3388, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3616, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3152, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3467, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2597, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3342, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3284, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2776, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3399, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3326, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3187, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2170, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2220, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2527, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2982, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2004, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2563, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2580, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3029, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1962, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2899, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3127, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1591, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3684, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2690, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1756, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2275, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3064, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2700, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2522, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1821, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1881, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2012, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1738, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3778, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3425, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2574, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2931, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1393, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2681, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4084, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3091, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2319, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2368, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3432, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3038, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3265, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2072, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2214, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2685, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3081, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3941, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2871, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2577, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2966, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2378, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2216, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2566, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2089, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1896, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2544, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3824, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2876, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2221, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2992, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1798, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1458, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2469, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2470, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2781, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2531, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1741, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3117, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2332, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2315, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2366, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2234, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1872, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2519, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3782, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2377, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2419, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1897, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1722, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2449, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3094, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3215, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3174, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2009, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2759, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1339, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1376, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1199, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1920, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.5155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2615, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0909, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1151, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2767, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3796, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1548, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2403, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1696, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2942, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1118, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1880, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2306, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2088, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1865, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1723, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1954, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1934, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2850, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2431, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2488, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2347, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1727, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1942, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2844, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2314, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1211, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1935, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1400, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3238, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2188, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3397, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1692, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1701, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2165, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2562, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0869, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2849, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2426, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1808, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4460, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2521, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2333, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2016, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2868, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2068, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2593, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1444, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆ     | 1/2 [00:59<00:59, 59.70s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "acbf7d96ed3741eab201cdc195fa85ea",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=250.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "tensor(0.1462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1922, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1228, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1461, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0726, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2542, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1184, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1060, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2398, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0332, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1177, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2618, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2941, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1675, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1505, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2632, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3386, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1509, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2479, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1660, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1166, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0588, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0659, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1231, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2587, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1560, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1695, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0269, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3154, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1121, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0892, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0649, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1480, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0670, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2924, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0718, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3031, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2805, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2393, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1286, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1475, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1131, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2286, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1289, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1835, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1547, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0763, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1150, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1371, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2042, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0809, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1292, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0673, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1815, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1584, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2046, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0467, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1806, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2556, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1915, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2133, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1711, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3475, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2247, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2069, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1274, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0532, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2658, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1384, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2277, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1059, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1478, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1838, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0525, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1039, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1686, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1778, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1653, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1283, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1925, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1257, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1189, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1485, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1536, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1015, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0739, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1263, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0416, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1737, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0780, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1482, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1215, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0599, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1900, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0579, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1481, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1185, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1055, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0491, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2267, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0172, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1908, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1133, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1316, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0852, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1428, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0960, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2168, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2646, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0462, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1259, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1757, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1230, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1860, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2329, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0790, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0988, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.4498, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.3065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1442, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1271, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1453, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1623, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1356, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2790, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1352, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1223, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0712, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0631, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1549, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2194, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0967, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1309, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1114, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1977, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1842, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0885, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1112, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0968, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1671, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0401, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1635, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0905, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1882, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0641, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0540, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1706, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2256, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0255, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2371, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0830, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0980, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1298, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2240, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1097, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0674, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0550, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0923, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1251, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1953, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1129, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0745, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1354, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2383, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1943, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1054, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0481, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1183, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0986, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1503, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2141, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2303, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1878, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1003, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2338, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1024, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0691, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0768, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0608, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1429, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0822, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1867, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.2268, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1006, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0389, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0857, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.0804, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1052, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "tensor(0.1978, device='cuda:0', grad_fn=<DivBackward0>)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2/2 [01:59<00:00, 59.78s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('outputs/Twitter_Sarcasm_Detection/vocab.txt',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ywxq1c8DSiV3"
      },
      "source": [
        "## 7. Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BChPy5tGaBwV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368,
          "referenced_widgets": [
            "f1b71b78fb3844b2ab946d4d16cdd889",
            "0991c21e3d2548b4ab357e435c4d0a0b",
            "27f618ec3a3141818fa3a417b448c0a0",
            "289fe412567849fbaaeffb256357b2bc",
            "2dc70257a14f4ca19e31d7aec6e000bc",
            "11ec9a1355194e72a711c62f84f51888",
            "d137866aaf0840538f6dbf7d9133bb96",
            "611cb406d3f84b5881ea22356735c7ae"
          ]
        },
        "outputId": "3a315080-d75b-40e2-a81d-801c274afa5d"
      },
      "source": [
        "model.eval()\n",
        "eval_loss = 0\n",
        "nb_eval_steps = 0\n",
        "preds = []\n",
        "\n",
        "for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(val_dataloader, desc=\"Evaluating\"):\n",
        "    input_ids = input_ids.to(device)\n",
        "    input_mask = input_mask.to(device)\n",
        "    segment_ids = segment_ids.to(device)\n",
        "    label_ids = label_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if BERT_MODEL in (BERT_PRETRAINED + alBERT_PRETRAINED + SqueezeBERT_PRETRAINED):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
        "        elif BERT_MODEL in (distilBERT_PRETRAINED + XLNet_PRETRAINED):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask, labels=label_ids)\n",
        "\n",
        "    logits = outputs.logits\n",
        "    tmp_eval_loss = outputs.loss\n",
        "\n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    nb_eval_steps += 1\n",
        "    if len(preds) == 0:\n",
        "        preds.append(logits.detach().cpu().numpy())\n",
        "    else:\n",
        "        preds[0] = np.append(\n",
        "            preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "eval_loss = eval_loss / nb_eval_steps\n",
        "preds = preds[0]\n",
        "\n",
        "if OUTPUT_MODE == \"classification\":\n",
        "    preds = np.argmax(preds, axis=1)\n",
        "elif OUTPUT_MODE == \"regression\":\n",
        "    preds = np.squeeze(preds)\n",
        "result = compute_metrics(TASK_NAME, val_label_ids.numpy(), preds, \\\n",
        "                         TRAIN_BATCH_SIZE, LEARNING_RATE, NUM_TRAIN_EPOCHS, GRADIENT_ACCUMULATION_STEPS)\n",
        "\n",
        "result['eval_loss'] = eval_loss\n",
        "\n",
        "output_eval_file = os.path.join(REPORTS_DIR, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    logger.info(\"***** Eval results *****\")\n",
        "    for key in (result.keys()):\n",
        "        logger.info(\"  %s = %s\", key, str(result[key]))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f1b71b78fb3844b2ab946d4d16cdd889",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Evaluating', max=32.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "INFO:root:***** Eval results *****\n",
            "INFO:root:  task = Twitter_Sarcasm_Detection\n",
            "INFO:root:  Batch Size = 16\n",
            "INFO:root:  Learning Rate = 2e-05\n",
            "INFO:root:  Epochs = 2\n",
            "INFO:root:  Gradient Accumulation Steps = 2\n",
            "INFO:root:  mcc = 0.643385626563087\n",
            "INFO:root:  tp = 455\n",
            "INFO:root:  tn = 364\n",
            "INFO:root:  fp = 126\n",
            "INFO:root:  fn = 55\n",
            "INFO:root:  Precision = 0.7831325301204819\n",
            "INFO:root:  Recall = 0.8921568627450981\n",
            "INFO:root:  F1 = 0.8340971585701191\n",
            "INFO:root:  eval_loss = 0.4368853932246566\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nDBtVu7JSbUK"
      },
      "source": [
        "## 8. Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l5fjf9f5fyIM",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 116,
          "referenced_widgets": [
            "c9a585c8757a492b9aa726a86f36b8cd",
            "e77cc1494f63403aac29b65f858752f1",
            "23581ddccd4f461eb0009953dc2b8294",
            "bd6fa9f673ba490899a1e32120cc01bd",
            "8520358d899b4a4c8adfdeeabe8d64ec",
            "a0e51fb74c1e4cabb368a32ffb2764cf",
            "b0317ff832594f3e8d6980dfefdce5a3",
            "1eb912d4d44148ca91103eeaf6b4cfaf"
          ]
        },
        "outputId": "e71ad1e8-eb27-4723-acd5-37bf857ff91c"
      },
      "source": [
        "test_preds = []\n",
        "\n",
        "for input_ids, input_mask, segment_ids in tqdm_notebook(test_dataloader, desc=\"Predicting\"):\n",
        "    input_ids = input_ids.to(device)\n",
        "    input_mask = input_mask.to(device)\n",
        "    segment_ids = segment_ids.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        if BERT_MODEL in (BERT_PRETRAINED + alBERT_PRETRAINED + SqueezeBERT_PRETRAINED):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=None)\n",
        "        elif BERT_MODEL in (distilBERT_PRETRAINED + XLNet_PRETRAINED):\n",
        "            outputs = model(input_ids=input_ids, attention_mask=input_mask, labels=None)\n",
        "\n",
        "    logits = outputs.logits\n",
        "\n",
        "    if len(test_preds) == 0:\n",
        "        test_preds.append(logits.detach().cpu().numpy())\n",
        "    else:\n",
        "        test_preds[0] = np.append(\n",
        "            test_preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "test_preds = test_preds[0]\n",
        "\n",
        "if OUTPUT_MODE == \"classification\":\n",
        "    test_preds = np.argmax(test_preds, axis=1)\n",
        "elif OUTPUT_MODE == \"regression\":\n",
        "    test_preds = np.squeeze(test_preds)\n",
        "\n",
        "w = open(f'outputs/{TASK_NAME}/answer.txt', 'w')\n",
        "\n",
        "for i in range(df_test.shape[0]):\n",
        "  if test_preds[i] == 1:\n",
        "    pred = 'SARCASM'\n",
        "  else:\n",
        "    pred = 'NOT_SARCASM'\n",
        "  w.writelines(df_test.at[i,'id'] + ',' + pred + '\\n')\n",
        "\n",
        "w.close()"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
            "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
            "  This is separate from the ipykernel package so we can avoid doing imports until\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c9a585c8757a492b9aa726a86f36b8cd",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Predicting', max=57.0, style=ProgressStyle(description_wiâ€¦"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3O8WlDifhuqD"
      },
      "source": [
        "## 9. Hyperparameter Tuning\r\n",
        "\r\n",
        "Please **DO NOT** run the following cell when reviewing / validating the project result. Otherwise it will take approximately 2 hours to finish the whole notebook.\r\n",
        "\r\n",
        "It is for hyperparameter tuning **ONLY**."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hn7vdUA3hyni"
      },
      "source": [
        "# csv_logger = CSVLogger(filename='/content/outputs/para_tune.csv',\n",
        "#                        fieldnames=['batch_size', 'iters_to_accumulate', 'learning_rate', 'epoch', \\\n",
        "#                                    'train_loss', 'train_precision', 'train_recall', 'train_f1', \\\n",
        "#                                    'val_loss', 'val_precision', 'val_recall', 'val_f1'])\n",
        "# set_seed(2020)\n",
        "# all_lrs = [2e-5, 5e-5, 1e-4]\n",
        "# all_eps = [1, 2, 3]\n",
        "# all_bs = [8, 16, 32]\n",
        "# all_gas = [1, 2, 3]\n",
        "\n",
        "# for bs in [16, 32]: # all_bs:\n",
        "#     train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=bs)\n",
        "\n",
        "#     for gas in all_gas:\n",
        "         \n",
        "#         for lr in all_lrs:\n",
        "#             optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "#                                  lr=lr,\n",
        "#                                  warmup=WARMUP_PROPORTION,\n",
        "#                                  t_total=num_train_optimization_steps)\n",
        "            \n",
        "#             for ep in all_eps:\n",
        "#                 num_train_optimization_steps = int(train_examples_len / bs / gas) * ep\n",
        "#                 optimizer = BertAdam(optimizer_grouped_parameters,\n",
        "#                                      lr=lr,\n",
        "#                                      warmup=WARMUP_PROPORTION,\n",
        "#                                      t_total=num_train_optimization_steps)  \n",
        "#                 print(\"Batch Size: \",bs,\", Gradient Accumu Steps: \",gas,\", Learning Rate: \",lr,\", Epochs: \",ep)\n",
        "\n",
        "#                 model.train()\n",
        "#                 global_step = 0\n",
        "\n",
        "#                 for i in trange(int(ep), desc=\"Epoch\"):\n",
        "                    \n",
        "#                     tr_loss = 0\n",
        "#                     nb_tr_examples = 0\n",
        "#                     nb_tr_steps = 0\n",
        "#                     train_preds = []\n",
        "#                     train_label_ids = []\n",
        "\n",
        "#                     for step, batch in enumerate(tqdm_notebook(train_dataloader, desc=\"Iteration\")):\n",
        "#                         batch = tuple(t.to(device) for t in batch)\n",
        "#                         input_ids, input_mask, segment_ids, label_ids = batch\n",
        "\n",
        "#                         if BERT_MODEL in (BERT_PRETRAINED + alBERT_PRETRAINED + SqueezeBERT_PRETRAINED):\n",
        "#                             outputs = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
        "#                         elif BERT_MODEL in (distilBERT_PRETRAINED + XLNet_PRETRAINED):\n",
        "#                             outputs = model(input_ids=input_ids, attention_mask=input_mask, labels=label_ids)\n",
        "\n",
        "#                         logits = outputs.logits\n",
        "#                         loss = outputs.loss\n",
        "\n",
        "#                         if gas > 1:\n",
        "#                             loss = loss / gas\n",
        "\n",
        "#                         loss.backward()\n",
        "                        \n",
        "#                         tr_loss += loss.item()\n",
        "#                         nb_tr_examples += input_ids.size(0)\n",
        "#                         nb_tr_steps += 1\n",
        "#                         if (step + 1) % gas == 0:\n",
        "#                             optimizer.step()\n",
        "#                             optimizer.zero_grad()\n",
        "#                             global_step += 1\n",
        "\n",
        "#                         if len(train_preds) == 0:\n",
        "#                             train_preds.append(logits.detach().cpu().numpy())\n",
        "#                         else:\n",
        "#                             train_preds[0] = np.append(\n",
        "#                                 train_preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "#                         if len(train_label_ids) == 0:\n",
        "#                             train_label_ids.append(label_ids.detach().cpu().numpy())\n",
        "#                         else:\n",
        "#                             train_label_ids[0] = np.append(\n",
        "#                                 train_label_ids[0], label_ids.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "#                     tr_loss = tr_loss / nb_tr_steps\n",
        "#                     train_preds = train_preds[0]\n",
        "#                     train_label_ids = train_label_ids[0]\n",
        "\n",
        "#                     if OUTPUT_MODE == \"classification\":\n",
        "#                         train_preds = np.argmax(train_preds, axis=1)\n",
        "#                     elif OUTPUT_MODE == \"regression\":\n",
        "#                         train_preds = np.squeeze(train_preds)\n",
        "\n",
        "#                     train_result = compute_metrics(TASK_NAME, train_label_ids, train_preds, bs, lr, ep, gas)\n",
        "#                     train_result['train_loss'] = tr_loss\n",
        "\n",
        "#                 model.eval()\n",
        "#                 eval_loss = 0\n",
        "#                 nb_eval_steps = 0\n",
        "#                 preds = []\n",
        "\n",
        "#                 for input_ids, input_mask, segment_ids, label_ids in tqdm_notebook(val_dataloader, desc=\"Evaluating\"):\n",
        "#                     input_ids = input_ids.to(device)\n",
        "#                     input_mask = input_mask.to(device)\n",
        "#                     segment_ids = segment_ids.to(device)\n",
        "#                     label_ids = label_ids.to(device)\n",
        "\n",
        "#                     with torch.no_grad():\n",
        "#                         if BERT_MODEL in (BERT_PRETRAINED + alBERT_PRETRAINED + SqueezeBERT_PRETRAINED):\n",
        "#                             outputs = model(input_ids=input_ids, attention_mask=input_mask, token_type_ids=segment_ids, labels=label_ids)\n",
        "#                         elif BERT_MODEL in (distilBERT_PRETRAINED + XLNet_PRETRAINED):\n",
        "#                             outputs = model(input_ids=input_ids, attention_mask=input_mask, labels=label_ids)\n",
        "\n",
        "#                     logits = outputs.logits\n",
        "#                     tmp_eval_loss = outputs.loss\n",
        "\n",
        "#                     eval_loss += tmp_eval_loss.mean().item()\n",
        "#                     nb_eval_steps += 1\n",
        "#                     if len(preds) == 0:\n",
        "#                         preds.append(logits.detach().cpu().numpy())\n",
        "#                     else:\n",
        "#                         preds[0] = np.append(\n",
        "#                             preds[0], logits.detach().cpu().numpy(), axis=0)\n",
        "\n",
        "#                 eval_loss = eval_loss / nb_eval_steps\n",
        "#                 preds = preds[0]\n",
        "\n",
        "#                 if OUTPUT_MODE == \"classification\":\n",
        "#                     preds = np.argmax(preds, axis=1)\n",
        "#                 elif OUTPUT_MODE == \"regression\":\n",
        "#                     preds = np.squeeze(preds)\n",
        "                \n",
        "#                 result = compute_metrics(TASK_NAME, val_label_ids.numpy(), preds, bs, lr, ep, gas)\n",
        "#                 result['val_loss'] = eval_loss\n",
        "\n",
        "#                 row = {'batch_size': str(bs), 'iters_to_accumulate': str(gas), 'learning_rate': str(lr), 'epoch': str(ep), \\\n",
        "#                        'train_loss': str(train_result['train_loss']), 'train_precision': str(train_result['Precision']), 'train_recall': str(train_result['Recall']), 'train_f1': str(train_result['F1']), \\\n",
        "#                        'val_loss': str(result['val_loss']), 'val_precision': str(result['Precision']), 'val_recall': str(result['Recall']), 'val_f1': str(result['F1'])}\n",
        "#                 csv_logger.writerow(row)\n",
        "# csv_logger.close()\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5E_JUrlTzbf"
      },
      "source": [
        "## 10. References\n",
        "\n",
        "- Huggingface Transformers Community Example: Fine-tune ALBERT for sentence-pair classification [`Fine_tune_ALBERT_sentence_pair_classification.ipynb`](https://github.com/NadirEM/nlp-notebooks/blob/master/Fine_tune_ALBERT_sentence_pair_classification.ipynb)\n",
        "\n",
        "- Huggingface Transformers Example: Movement Pruning Adaptive Sparsity by Fine-Tuning [`masked_run_glue.py`](https://github.com/huggingface/transformers/blob/67ff1c314a61a2d5949b3bb48fa3ec7e9b697d7e/examples/movement-pruning/masked_run_glue.py)\n",
        "\n",
        "- [Huggingface Transformers Notebooks](https://github.com/huggingface/transformers/tree/master/notebooks)\n",
        "\n",
        "- [Huggingface Transformers Quick Start](https://huggingface.co/transformers/quickstart.html)\n",
        "\n",
        "- Huggingface Transformers Tutorial: Fine Tuning Transformer for MultiLabel Text Classification [`transformers_multi_label_classification.ipynb`](https://github.com/abhimishra91/transformers-tutorials/blob/master/transformers_multi_label_classification.ipynb)\n",
        "\n",
        "- Off-the-shelf BERT classifier by Google Research [`run_classifier.py`](https://github.com/google-research/bert/blob/master/run_classifier.py)\n",
        "\n",
        "- [Pre-trained Models](https://huggingface.co/transformers/pretrained_models.html)\n",
        "\n",
        "- [Simple Guide On Using BERT for Binary Text Classification](https://medium.com/swlh/a-simple-guide-on-using-bert-for-text-classification-bbf041ac8d04)\n",
        "\n",
        "- Check GPU memory[`PyTorch_Reformer.ipynb`](https://github.com/patrickvonplaten/notebooks/blob/master/PyTorch_Reformer.ipynb)"
      ]
    }
  ]
}